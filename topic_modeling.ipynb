{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Testing topic modeling on a tripadvisor reviews dataset\n",
    "\n",
    "1. Load the dataset and preprocess the reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba74ccb949e795d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amato\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# if you have incompatibility problems between gensim and scipy:\n",
    "# - uninstall current version of scipy\n",
    "# - run `pip install scipy==1.10.1`"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:52.654148Z",
     "start_time": "2024-04-12T09:58:52.632510Z"
    }
   },
   "id": "8c7d4f0f15fd2b06",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the dataset and preprocess the reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ccda62bbfa7bd3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(review: str) -> List[str]:\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    # remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # keep only nouns\n",
    "    tokens = [word for word, pos in pos_tag(tokens) if pos.startswith('N')]\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:52.794291Z",
     "start_time": "2024-04-12T09:58:52.767935Z"
    }
   },
   "id": "302e296dd75c49fc",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fd391458c56773"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'reviews_preprocessed.txt' not in os.listdir('resources'):\n",
    "    # preprocess the reviews\n",
    "    df = pd.read_csv('resources/reviews.csv', nrows=1000)\n",
    "    reviews = df['Review']\n",
    "    reviews = [review.strip() for review in reviews] # remove newline characters from each review\n",
    "    # remove punctuation, stopwords, lemmatize and keep only nouns\n",
    "    reviews = [preprocess(review) for review in reviews]\n",
    "else:\n",
    "    # load the preprocessed reviews\n",
    "    reviews = []\n",
    "    with open('resources/reviews_preprocessed.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            reviews.append(line.strip().split(','))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:52.950336Z",
     "start_time": "2024-04-12T09:58:52.881427Z"
    }
   },
   "id": "5dfc023a3d041928",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['hotel',\n 'parking',\n 'deal',\n 'hotel',\n 'evening',\n 'review',\n 'valet',\n 'check',\n 'view',\n 'room',\n 'room',\n 'size',\n 'woke',\n 'pillow',\n 'soundproof',\n 'heard',\n 'music',\n 'room',\n 'night',\n 'morning',\n 'loud',\n 'bang',\n 'door',\n 'closing',\n 'people',\n 'neighbor',\n 'bath',\n 'product',\n 'stay',\n 'advantage',\n 'location',\n 'distance',\n 'experience',\n 'pay',\n 'parking',\n 'night']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how the first review looks like after preprocessing\n",
    "reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:53.184632Z",
     "start_time": "2024-04-12T09:58:53.145187Z"
    }
   },
   "id": "87a542a9923694e0",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'reviews_preprocessed.txt' not in os.listdir('resources'):\n",
    "    # save the preprocessed reviews to a file\n",
    "    with open('resources/reviews_preprocessed.txt', 'w') as f:\n",
    "        for review in reviews:\n",
    "            f.write(','.join(review) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:53.306498Z",
     "start_time": "2024-04-12T09:58:53.273624Z"
    }
   },
   "id": "5156edf598d63c8d",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Dictionary and Corpus\n",
    "\n",
    "# Create a dictionary from the processed reviews.\n",
    "# This dictionary encapsulates the mapping between normalized words (nouns in this case) and their integer ids.\n",
    "# Each unique word is assigned a unique id.\n",
    "dictionary = corpora.Dictionary(reviews)\n",
    "\n",
    "# Create a corpus from the processed reviews using the dictionary.\n",
    "# The corpus is a list of documents where each document is represented as a list of tuples.\n",
    "# Each tuple consists of a word's integer id and its frequency in the document.\n",
    "# This method converts each document (a list of words) into the bag-of-words format.\n",
    "corpus = [dictionary.doc2bow(text) for text in reviews]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:54.040336Z",
     "start_time": "2024-04-12T09:58:53.367123Z"
    }
   },
   "id": "6ec70fac018cf221",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T09:58:54.070742Z",
     "start_time": "2024-04-12T09:58:54.044881Z"
    }
   },
   "id": "395a4408f890ebcb",
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
