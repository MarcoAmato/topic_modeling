{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Testing topic modeling on a tripadvisor reviews dataset\n",
    "\n",
    "1. Load the dataset and preprocess the reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba74ccb949e795d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amato\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# if you have incompatibility problems between gensim and scipy:\n",
    "# - uninstall current version of scipy\n",
    "# - run `pip install scipy==1.10.1`"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:07.782856Z",
     "start_time": "2024-04-12T10:24:07.759772Z"
    }
   },
   "id": "8c7d4f0f15fd2b06",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the dataset and preprocess the reviews"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ccda62bbfa7bd3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(review: str) -> List[str]:\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    # remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # keep only nouns\n",
    "    tokens = [word for word, pos in pos_tag(tokens) if pos.startswith('N')]\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:07.956248Z",
     "start_time": "2024-04-12T10:24:07.929056Z"
    }
   },
   "id": "302e296dd75c49fc",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fd391458c56773"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'reviews_preprocessed.txt' not in os.listdir('resources'):\n",
    "    # preprocess the reviews\n",
    "    df = pd.read_csv('resources/reviews.csv', nrows=1000)\n",
    "    reviews = df['Review']\n",
    "    reviews = [review.strip() for review in reviews] # remove newline characters from each review\n",
    "    # remove punctuation, stopwords, lemmatize and keep only nouns\n",
    "    reviews = [preprocess(review) for review in reviews]\n",
    "else:\n",
    "    # load the preprocessed reviews\n",
    "    reviews = []\n",
    "    with open('resources/reviews_preprocessed.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            reviews.append(line.strip().split(','))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.095403Z",
     "start_time": "2024-04-12T10:24:08.043069Z"
    }
   },
   "id": "5dfc023a3d041928",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['hotel',\n 'parking',\n 'deal',\n 'hotel',\n 'evening',\n 'review',\n 'valet',\n 'check',\n 'view',\n 'room',\n 'room',\n 'size',\n 'woke',\n 'pillow',\n 'soundproof',\n 'heard',\n 'music',\n 'room',\n 'night',\n 'morning',\n 'loud',\n 'bang',\n 'door',\n 'closing',\n 'people',\n 'neighbor',\n 'bath',\n 'product',\n 'stay',\n 'advantage',\n 'location',\n 'distance',\n 'experience',\n 'pay',\n 'parking',\n 'night']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how the first review looks like after preprocessing\n",
    "reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.250861Z",
     "start_time": "2024-04-12T10:24:08.229091Z"
    }
   },
   "id": "87a542a9923694e0",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'reviews_preprocessed.txt' not in os.listdir('resources'):\n",
    "    # save the preprocessed reviews to a file\n",
    "    with open('resources/reviews_preprocessed.txt', 'w') as f:\n",
    "        for review in reviews:\n",
    "            f.write(','.join(review) + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.373484Z",
     "start_time": "2024-04-12T10:24:08.349601Z"
    }
   },
   "id": "5156edf598d63c8d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Dictionary and Corpus\n",
    "\n",
    "# Create a dictionary from the processed reviews.\n",
    "# This dictionary encapsulates the mapping between normalized words (nouns in this case) and their integer ids.\n",
    "# Each unique word is assigned a unique id.\n",
    "dictionary = corpora.Dictionary(reviews)\n",
    "\n",
    "# Create a corpus from the processed reviews using the dictionary.\n",
    "# The corpus is a list of documents where each document is represented as a list of tuples.\n",
    "# Each tuple consists of a word's integer id and its frequency in the document.\n",
    "# This method converts each document (a list of words) into the bag-of-words format.\n",
    "corpus = [dictionary.doc2bow(text) for text in reviews]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.860995Z",
     "start_time": "2024-04-12T10:24:08.480458Z"
    }
   },
   "id": "6ec70fac018cf221",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Sample:\n",
      "ID 0: advantage\n",
      "ID 1: bang\n",
      "ID 2: bath\n",
      "ID 3: check\n",
      "ID 4: closing\n",
      "ID 5: deal\n",
      "ID 6: distance\n",
      "ID 7: door\n",
      "ID 8: evening\n",
      "ID 9: experience\n",
      "\n",
      "\n",
      "Corpus Sample:\n",
      "[('advantage', 1), ('bang', 1), ('bath', 1), ('check', 1), ('closing', 1), ('deal', 1), ('distance', 1), ('door', 1), ('evening', 1), ('experience', 1)]\n"
     ]
    }
   ],
   "source": [
    "# print dictionary sample\n",
    "print(\"Dictionary Sample:\")\n",
    "for i, (word_id, word) in enumerate(dictionary.iteritems()):\n",
    "    print(f\"ID {word_id}: {word}\")\n",
    "    if i == 9:  # limit to the first 10 items\n",
    "        break\n",
    "        \n",
    "print(\"\\n\")\n",
    "\n",
    "# Print corpus sample\n",
    "# Print the BoW representation for the first 3 documents in the corpus.\n",
    "print(\"Corpus Sample:\")\n",
    "# Formatting output to show word counts along with their corresponding words\n",
    "formatted_doc = [(dictionary[word_id], count) for word_id, count in corpus[0]]\n",
    "print(formatted_doc[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.937682Z",
     "start_time": "2024-04-12T10:24:08.881215Z"
    }
   },
   "id": "395a4408f890ebcb",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 3: LDA Model\n",
    "def run_lda(corpus, dictionary, num_topics):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                num_topics=num_topics,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                per_word_topics=True)\n",
    "    return lda_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:08.982831Z",
     "start_time": "2024-04-12T10:24:08.944504Z"
    }
   },
   "id": "38f69d0563ff2ef6",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 4: Evaluate Models\n",
    "def evaluate_models(corpus, dictionary, texts, start, limit, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = run_lda(corpus, dictionary, num_topics)\n",
    "        model_list.append(model)\n",
    "        # CoherenceModel evaluates the topic modeling for a certain model https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:24:09.044083Z",
     "start_time": "2024-04-12T10:24:08.999038Z"
    }
   },
   "id": "c4f4e37003ed67ba",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.3682\n",
      "Num Topics = 3  has Coherence Value of 0.3922\n",
      "Num Topics = 4  has Coherence Value of 0.4311\n",
      "Num Topics = 5  has Coherence Value of 0.4567\n",
      "Num Topics = 6  has Coherence Value of 0.413\n",
      "Num Topics = 7  has Coherence Value of 0.4716\n",
      "Num Topics = 8  has Coherence Value of 0.4401\n",
      "Num Topics = 9  has Coherence Value of 0.5054\n",
      "Num Topics = 10  has Coherence Value of 0.4384\n",
      "Num Topics = 11  has Coherence Value of 0.4697\n",
      "Num Topics = 12  has Coherence Value of 0.4536\n",
      "Num Topics = 13  has Coherence Value of 0.4399\n",
      "Num Topics = 14  has Coherence Value of 0.4539\n"
     ]
    }
   ],
   "source": [
    "# Run and evaluate models\n",
    "model_list, coherence_values = evaluate_models(corpus, dictionary, reviews, start=2, limit=15, step=1)\n",
    "\n",
    "# Print coherence values to choose the best model\n",
    "for m, cv in zip(range(2, 15), coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T10:28:53.369343Z",
     "start_time": "2024-04-12T10:24:09.051196Z"
    }
   },
   "id": "636bfb5a83bca3b",
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
